{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow so we can use it.\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use Tensorflow\n",
    "# Like in regular algebra, we have variables that will stand for values\n",
    "#In python\n",
    "x = 3\n",
    "# In TF, although this seems convoluted, it is doing the same thing as the above code\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(9, name=\"y\")\n",
    "# variable_name = tf.Variable(value, name=\"name_given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, look at the following function\n",
    "f = x * y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In TF we have to activate our variables to use them, like so:\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate a session\n",
    "with tf.Session() as sess:\n",
    "    init.run() # Initialize variables in the session\n",
    "    result = f.eval() # Store the result of f (x * y + 2) in result. Eval runs the result of f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Slides for explanation of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn comes with pre imported datasets, this MNIST dataset is one of the most popular ones\n",
    "mnist = fetch_mldata(\"MNIST original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our mnist variable contains our actual data and our labels, X and y\n",
    "X = mnist[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's visualise what X and y are\n",
    "# We check the shape of x and see its a matrix of 70k rows and 784 columns\n",
    "# This means that we have 70k images\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why is y only one array of 70k elements? Our y array has the \"result\" or \"target of each 784 size array\n",
    "# This means that for every image there is an \"answer\"\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize a single digit\n",
    "# Here we access a random digit located at position 1200\n",
    "plotting_digit = X[19801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see each digit is an array of 784\n",
    "plotting_digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is because a digit is a 28x28(784 pixels) image. So basically we have like 70k arrays whose size are 784\n",
    "# So we have an array of pixels, where the number of the pixel is the intensity of the pixel from [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABJ5JREFUeJzt3UFu4kgYgNF4lHsRTgacLMnJmE1vejRUoXaMab73tg5gpHyqxU+Vl+v1+gb0/LP3DQD7ED9EiR+ixA9R4oco8UOU+CFK/BAlfoh6f/Dn+TkhbG+554+s/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHqPe9b4B9fX19rbq+pcvlstl7f3x8DK9/fn5u9tnPwsoPUeKHKPFDlPghSvwQJX6IEj9ELdfr9ZGf99APqxjN4o/H4+Nu5IWcTqfh9fP5/Jgb+TPLPX9k5Yco8UOU+CFK/BAlfogSP0TZ0vsC9tx2+7eabel98lHej7DyQ5T4IUr8ECV+iBI/RIkfosQPUbb0vrjZlt7D4TC8vnbeved249Es/8WP5ralF7hN/BAlfogSP0SJH6LED1HihyhzflaZzeq3PGtgNquf7dl/Yeb8wG3ihyjxQ5T4IUr8ECV+iBI/RDm3P262X/9yuTzmRv6HOf62rPwQJX6IEj9EiR+ixA9R4oco8UOUOf8L2PNs/JnRLP50Ov3xa1nPyg9R4oco8UOU+CFK/BAlfogy6vsLzI6/3nOcNxvHjcZ5Rnn7svJDlPghSvwQJX6IEj9EiR+ixA9RHtH9BJ55jr+nNb8huOf1L8wjuoHbxA9R4oco8UOU+CFK/BAlfogy538Cy3LXWJb/mM3xZ4/4fmHm/MBt4oco8UOU+CFK/BAlfogSP0SZ8z+B2X7+y+UyvH44HH7wbp7H7HvPjPb7n8/nVe/95Mz5gdvED1HihyjxQ5T4IUr8ECV+iHrf+waY70uvnj+/ds7PmJUfosQPUeKHKPFDlPghSvwQZdTHbqqPHn8WVn6IEj9EiR+ixA9R4oco8UOU+CHK0d1sanQs+do5v0d03+TobuA28UOU+CFK/BAlfogSP0SJH6Ls52eV2aOutzx+e/QIbuas/BAlfogSP0SJH6LED1HihyjxQ5Q5/51G8+y1s+wHn6nwm9F++7e3+XebvX6N2X786qPLf4qVH6LED1HihyjxQ5T4IUr8EGXU98vakdfI1iOp0b1v+b3WMsrbl5UfosQPUeKHKPFDlPghSvwQJX6IMuf/ZcutqYfDYXh9dvz19/f38PqW9z4zOz57NKs3x9+XlR+ixA9R4oco8UOU+CFK/BAlfohaHnxs9H5nVK+0LMvet7CJ2ax97W8U2MVd/6xWfogSP0SJH6LED1HihyjxQ5T4Icp+/juNzpg/Ho+bfvaaWbw5PLdY+SFK/BAlfogSP0SJH6LED1Hihyj7+eH12M8P3CZ+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6hHP6L7riOFge1Z+SFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oeofwF71LAx9LIbRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123466b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember that if we plot a digit as it is we will see just a line because it is one-dimensional\n",
    "# So we reshape it to become an image of 28 by 28\n",
    "plotting_digit_image = plotting_digit.reshape(28, 28)\n",
    "# Here we set up the plot with our digit\n",
    "plt.imshow(plotting_digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "# Here we hide the axis (because we don't need an x-y orientation)\n",
    "plt.axis(\"off\")\n",
    "#Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see a 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 128, 128,\n",
       "       128, 128, 255, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 128,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 191,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 191, 128,   0,   0,  64, 255, 255, 255, 191,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 191, 255, 255, 255,  64,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 128, 255, 255, 255, 255,  64,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255, 255, 191,\n",
       "        64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255, 255,\n",
       "       191,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 191,  64,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 191,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        64, 191, 128, 128, 128, 128, 128, 128, 128, 255, 255, 128,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255,\n",
       "       128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 191,\n",
       "       255, 255, 128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        64, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 128, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 128, 255, 255,   0,   0,   0,\n",
       "         0,  64, 191, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 191,   0,\n",
       "         0,  64, 128, 255, 255, 255, 255,  64,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 255, 255,\n",
       "       128, 128, 191, 255, 255, 255, 255, 128,  64,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       255, 255, 255, 255, 255, 255, 255, 191, 128,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  64, 255, 255, 255, 191, 128,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But how does it look actually?\n",
    "plotting_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you look from far enough you can kind of see the 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at what our results say\n",
    "# Remember we got the 19801th row so our 19801th row in y should be it's assigned answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Great! As you can see, no more arrays, but rather y is an array of 70k numbers. Our answers.\n",
    "y[19801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how are we going to train a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to train it on our X and then check if they match our Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we should maybe leave some of our elements in X and y to test out if it actually works\n",
    "# Because it is useless if we test on the data we trained on! The algorithm has to see new data for use to know it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fortunately sklearn has a function that does this for us. It also shuffles the data which is good practice\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we assign our new testing and training data and split them 80-20 or 0.2*70,000 = 56000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 784)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the data ready let's build the Neural Net!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_test[0].size # (784)\n",
    "size_hidden_layer1 = 200\n",
    "size_hidden_layer2 = 50\n",
    "number_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare an X and y variables with their respetive size (X will contain n amount of examples all of size input_size)\n",
    "# y will contain n answers to the n examples of X\n",
    "# Our data will be transmitted to the network through X\n",
    "X = tf.placeholder(tf.float32, shape=(None, input_size), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a name for the scope of this block of code (helps with organization)\n",
    "with tf.name_scope(\"deep_network\"):\n",
    "    # Declare our first hidden layer. Takes X as an input (our data), of size size_hidde...\n",
    "    hidden1 = tf.layers.dense(X, size_hidden_layer1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    # Declare our second hidden layer. It takes the output of our first hidden layer, of size size_hide...\n",
    "    hidden2 = tf.layers.dense(hidden1, size_hidden_layer2, name=\"hidden_layer2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    # Our third and final layer returns the output and takes in hidden2\n",
    "    output = tf.layers.dense(hidden2, number_outputs, name=\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our loss function that we will use as basis of training\n",
    "with tf.name_scope(\"loss_cross_entropy\"):\n",
    "    # We use the cross entropy loss function with softmax as we saw in the slides with our according labels and our results\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "    # Get the mean error from all exapmples so \n",
    "    loss = tf.reduce_mean(cross_entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to declare an optimizer that will act on our loss and tweak the params accordingly\n",
    "\n",
    "# Declare learning_rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Use the Gradient Descent Optimizer and give it our learning rate (the size of our steps)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we state our measure, that is, what are we aiming for\n",
    "# In this case we will use accuracy\n",
    "with tf.name_scope(\"evaluation\"):\n",
    "    # For each example determine if the prediction (our output) is equal to \n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
